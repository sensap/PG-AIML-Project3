{"cells":[{"cell_type":"markdown","metadata":{"id":"9a54fa0f"},"source":["# Credit Card Users Churn Prediction"]},{"cell_type":"markdown","metadata":{"id":"9EaJ8AGwpM-2"},"source":["## Problem Statement"]},{"cell_type":"markdown","metadata":{"id":"x3-QehJxbp0t"},"source":["### Business Context\n","\n","The Thera bank recently saw a steep decline in the number of users of their credit card, credit cards are a good source of income for banks because of different kinds of fees charged by the banks like annual fees, balance transfer fees, and cash advance fees, late payment fees, foreign transaction fees, and others. Some fees are charged to every user irrespective of usage, while others are charged under specified circumstances.\n","\n","Customers’ leaving credit cards services would lead bank to loss, so the bank wants to analyze the data of customers and identify the customers who will leave their credit card services and reason for same – so that bank could improve upon those areas\n","\n","You as a Data scientist at Thera bank need to come up with a classification model that will help the bank improve its services so that customers do not renounce their credit cards\n","\n","### Data Description\n","\n","* CLIENTNUM: Client number. Unique identifier for the customer holding the account\n","* Attrition_Flag: Internal event (customer activity) variable - if the account is closed then \"Attrited Customer\" else \"Existing Customer\"\n","* Customer_Age: Age in Years\n","* Gender: Gender of the account holder\n","* Dependent_count: Number of dependents\n","* Education_Level: Educational Qualification of the account holder - Graduate, High School, Unknown, Uneducated, College(refers to college student), Post-Graduate, Doctorate\n","* Marital_Status: Marital Status of the account holder\n","* Income_Category: Annual Income Category of the account holder\n","* Card_Category: Type of Card\n","* Months_on_book: Period of relationship with the bank (in months)\n","* Total_Relationship_Count: Total no. of products held by the customer\n","* Months_Inactive_12_mon: No. of months inactive in the last 12 months\n","* Contacts_Count_12_mon: No. of Contacts in the last 12 months\n","* Credit_Limit: Credit Limit on the Credit Card\n","* Total_Revolving_Bal: Total Revolving Balance on the Credit Card\n","* Avg_Open_To_Buy: Open to Buy Credit Line (Average of last 12 months)\n","* Total_Amt_Chng_Q4_Q1: Change in Transaction Amount (Q4 over Q1)\n","* Total_Trans_Amt: Total Transaction Amount (Last 12 months)\n","* Total_Trans_Ct: Total Transaction Count (Last 12 months)\n","* Total_Ct_Chng_Q4_Q1: Change in Transaction Count (Q4 over Q1)\n","* Avg_Utilization_Ratio: Average Card Utilization Ratio\n","\n","#### What Is a Revolving Balance?\n","\n","- If we don't pay the balance of the revolving credit account in full every month, the unpaid portion carries over to the next month. That's called a revolving balance\n","\n","\n","##### What is the Average Open to buy?\n","\n","- 'Open to Buy' means the amount left on your credit card to use. Now, this column represents the average of this value for the last 12 months.\n","\n","##### What is the Average utilization Ratio?\n","\n","- The Avg_Utilization_Ratio represents how much of the available credit the customer spent. This is useful for calculating credit scores.\n","\n","\n","##### Relation b/w Avg_Open_To_Buy, Credit_Limit and Avg_Utilization_Ratio:\n","\n","- ( Avg_Open_To_Buy / Credit_Limit ) + Avg_Utilization_Ratio = 1"]},{"cell_type":"markdown","metadata":{"id":"NbHOIdlwcrqR"},"source":["### **Please read the instructions carefully before starting the project.**\n","This is a commented Jupyter IPython Notebook file in which all the instructions and tasks to be performed are mentioned.\n","* Blanks '_______' are provided in the notebook that\n","needs to be filled with an appropriate code to get the correct result. With every '_______' blank, there is a comment that briefly describes what needs to be filled in the blank space.\n","* Identify the task to be performed correctly, and only then proceed to write the required code.\n","* Fill the code wherever asked by the commented lines like \"# write your code here\" or \"# complete the code\". Running incomplete code may throw error.\n","* Please run the codes in a sequential manner from the beginning to avoid any unnecessary errors.\n","* Add the results/observations (wherever mentioned) derived from the analysis in the presentation and submit the same.\n"]},{"cell_type":"markdown","metadata":{"id":"v_-uuGqH-qTt"},"source":["## Importing necessary libraries"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting xgboost\n","  Downloading xgboost-2.0.3-py3-none-win_amd64.whl.metadata (2.0 kB)\n","Requirement already satisfied: numpy in c:\\users\\sethanga\\appdata\\local\\anaconda3\\envs\\learning\\lib\\site-packages (from xgboost) (1.26.2)\n","Requirement already satisfied: scipy in c:\\users\\sethanga\\appdata\\local\\anaconda3\\envs\\learning\\lib\\site-packages (from xgboost) (1.11.4)\n","Downloading xgboost-2.0.3-py3-none-win_amd64.whl (99.8 MB)\n","   ---------------------------------------- 0.0/99.8 MB ? eta -:--:--\n","   ---------------------------------------- 0.0/99.8 MB ? eta -:--:--\n","   ---------------------------------------- 0.0/99.8 MB ? eta -:--:--\n","   ---------------------------------------- 0.0/99.8 MB 330.3 kB/s eta 0:05:02\n","   ---------------------------------------- 0.1/99.8 MB 469.7 kB/s eta 0:03:33\n","   ---------------------------------------- 0.3/99.8 MB 2.0 MB/s eta 0:00:49\n","   ---------------------------------------- 1.2/99.8 MB 6.1 MB/s eta 0:00:17\n","    --------------------------------------- 2.2/99.8 MB 8.8 MB/s eta 0:00:12\n","   - -------------------------------------- 3.8/99.8 MB 12.8 MB/s eta 0:00:08\n","   -- ------------------------------------- 5.3/99.8 MB 15.4 MB/s eta 0:00:07\n","   -- ------------------------------------- 6.5/99.8 MB 16.7 MB/s eta 0:00:06\n","   --- ------------------------------------ 9.0/99.8 MB 20.5 MB/s eta 0:00:05\n","   ---- ----------------------------------- 10.7/99.8 MB 32.8 MB/s eta 0:00:03\n","   ----- ---------------------------------- 12.8/99.8 MB 38.6 MB/s eta 0:00:03\n","   ----- ---------------------------------- 14.5/99.8 MB 38.5 MB/s eta 0:00:03\n","   ------ --------------------------------- 16.4/99.8 MB 43.7 MB/s eta 0:00:02\n","   ------- -------------------------------- 18.4/99.8 MB 40.9 MB/s eta 0:00:02\n","   -------- ------------------------------- 20.3/99.8 MB 40.9 MB/s eta 0:00:02\n","   -------- ------------------------------- 22.0/99.8 MB 38.5 MB/s eta 0:00:03\n","   --------- ------------------------------ 24.0/99.8 MB 40.9 MB/s eta 0:00:02\n","   ---------- ----------------------------- 25.4/99.8 MB 38.6 MB/s eta 0:00:02\n","   ---------- ----------------------------- 27.3/99.8 MB 38.6 MB/s eta 0:00:02\n","   ----------- ---------------------------- 28.9/99.8 MB 36.4 MB/s eta 0:00:02\n","   ------------ --------------------------- 30.5/99.8 MB 36.4 MB/s eta 0:00:02\n","   ------------ --------------------------- 32.2/99.8 MB 36.4 MB/s eta 0:00:02\n","   ------------- -------------------------- 33.9/99.8 MB 34.4 MB/s eta 0:00:02\n","   -------------- ------------------------- 35.6/99.8 MB 38.5 MB/s eta 0:00:02\n","   -------------- ------------------------- 37.1/99.8 MB 34.6 MB/s eta 0:00:02\n","   --------------- ------------------------ 38.8/99.8 MB 36.3 MB/s eta 0:00:02\n","   ---------------- ----------------------- 40.6/99.8 MB 36.3 MB/s eta 0:00:02\n","   ---------------- ----------------------- 42.3/99.8 MB 36.4 MB/s eta 0:00:02\n","   ----------------- ---------------------- 44.1/99.8 MB 38.6 MB/s eta 0:00:02\n","   ------------------ --------------------- 46.0/99.8 MB 38.6 MB/s eta 0:00:02\n","   ------------------- -------------------- 47.9/99.8 MB 40.9 MB/s eta 0:00:02\n","   ------------------- -------------------- 49.6/99.8 MB 40.9 MB/s eta 0:00:02\n","   -------------------- ------------------- 51.5/99.8 MB 40.9 MB/s eta 0:00:02\n","   --------------------- ------------------ 53.2/99.8 MB 40.9 MB/s eta 0:00:02\n","   ---------------------- ----------------- 55.2/99.8 MB 40.9 MB/s eta 0:00:02\n","   ---------------------- ----------------- 56.9/99.8 MB 38.6 MB/s eta 0:00:02\n","   ----------------------- ---------------- 58.7/99.8 MB 38.6 MB/s eta 0:00:02\n","   ------------------------ --------------- 60.7/99.8 MB 38.6 MB/s eta 0:00:02\n","   ------------------------- -------------- 62.5/99.8 MB 38.5 MB/s eta 0:00:01\n","   ------------------------- -------------- 64.2/99.8 MB 38.5 MB/s eta 0:00:01\n","   -------------------------- ------------- 66.2/99.8 MB 38.5 MB/s eta 0:00:01\n","   --------------------------- ------------ 68.2/99.8 MB 40.9 MB/s eta 0:00:01\n","   ---------------------------- ----------- 70.0/99.8 MB 43.7 MB/s eta 0:00:01\n","   ---------------------------- ----------- 71.6/99.8 MB 40.9 MB/s eta 0:00:01\n","   ----------------------------- ---------- 73.3/99.8 MB 40.9 MB/s eta 0:00:01\n","   ------------------------------ --------- 75.2/99.8 MB 40.9 MB/s eta 0:00:01\n","   ------------------------------ --------- 76.9/99.8 MB 38.6 MB/s eta 0:00:01\n","   ------------------------------- -------- 78.6/99.8 MB 38.6 MB/s eta 0:00:01\n","   -------------------------------- ------- 80.1/99.8 MB 36.4 MB/s eta 0:00:01\n","   --------------------------------- ------ 82.3/99.8 MB 38.5 MB/s eta 0:00:01\n","   --------------------------------- ------ 84.2/99.8 MB 38.5 MB/s eta 0:00:01\n","   ---------------------------------- ----- 86.1/99.8 MB 40.9 MB/s eta 0:00:01\n","   ----------------------------------- ---- 88.0/99.8 MB 40.9 MB/s eta 0:00:01\n","   ------------------------------------ --- 89.8/99.8 MB 40.9 MB/s eta 0:00:01\n","   ------------------------------------ --- 91.6/99.8 MB 40.9 MB/s eta 0:00:01\n","   ------------------------------------- -- 93.6/99.8 MB 40.9 MB/s eta 0:00:01\n","   -------------------------------------- - 95.4/99.8 MB 40.9 MB/s eta 0:00:01\n","   -------------------------------------- - 97.1/99.8 MB 38.5 MB/s eta 0:00:01\n","   ---------------------------------------  99.2/99.8 MB 40.9 MB/s eta 0:00:01\n","   ---------------------------------------  99.7/99.8 MB 40.9 MB/s eta 0:00:01\n","   ---------------------------------------  99.7/99.8 MB 40.9 MB/s eta 0:00:01\n","   ---------------------------------------  99.7/99.8 MB 40.9 MB/s eta 0:00:01\n","   ---------------------------------------  99.7/99.8 MB 40.9 MB/s eta 0:00:01\n","   ---------------------------------------  99.7/99.8 MB 40.9 MB/s eta 0:00:01\n","   ---------------------------------------  99.7/99.8 MB 40.9 MB/s eta 0:00:01\n","   ---------------------------------------  99.7/99.8 MB 40.9 MB/s eta 0:00:01\n","   ---------------------------------------  99.7/99.8 MB 40.9 MB/s eta 0:00:01\n","   ---------------------------------------- 99.8/99.8 MB 16.0 MB/s eta 0:00:00\n","Installing collected packages: xgboost\n","Successfully installed xgboost-2.0.3\n","Note: you may need to restart the kernel to use updated packages.\n","Collecting lightgbm\n","  Downloading lightgbm-4.3.0-py3-none-win_amd64.whl.metadata (19 kB)\n","Requirement already satisfied: numpy in c:\\users\\sethanga\\appdata\\local\\anaconda3\\envs\\learning\\lib\\site-packages (from lightgbm) (1.26.2)\n","Requirement already satisfied: scipy in c:\\users\\sethanga\\appdata\\local\\anaconda3\\envs\\learning\\lib\\site-packages (from lightgbm) (1.11.4)\n","Downloading lightgbm-4.3.0-py3-none-win_amd64.whl (1.3 MB)\n","   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n","   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n","   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n","   - -------------------------------------- 0.1/1.3 MB 656.4 kB/s eta 0:00:02\n","   ----- ---------------------------------- 0.2/1.3 MB 1.5 MB/s eta 0:00:01\n","   ----------------------- ---------------- 0.8/1.3 MB 4.5 MB/s eta 0:00:01\n","   ---------------------------------------  1.3/1.3 MB 6.5 MB/s eta 0:00:01\n","   ---------------------------------------- 1.3/1.3 MB 5.7 MB/s eta 0:00:00\n","Installing collected packages: lightgbm\n","Successfully installed lightgbm-4.3.0\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["%pip install xgboost\n","%pip install lightgbm"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"83D17_Wl4jal"},"outputs":[],"source":["# Pandas and numpy for data manipulation\n","import pandas as pd\n","import numpy as np\n","\n","# Data Visualization\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Train Test Split\n","from sklearn.model_selection import train_test_split\n"," \n","from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc, roc_auc_score\n","\n","#DecisionTreeClassifier, DecisionTreeRegressor, ExtraTreeClassifier, ExtraTreeRegressor\n","from sklearn.tree import DecisionTreeClassifier\n","\n","# Random Forest, AdaBoost, Gradient Boosting, Bagging, XGBoost classifiers\n","from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, BaggingClassifier\n","\n","# XGBClassifier\n","from xgboost import XGBClassifier\n","  \n","# Under Sampling and Over Sampling\n","from imblearn.under_sampling import RandomUnderSampler\n","from imblearn.over_sampling import SMOTE\n","\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n"]},{"cell_type":"markdown","metadata":{"id":"xxhpZv9y-qTw"},"source":["## Loading the dataset"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"oJnKoHy14jam"},"outputs":[],"source":["df = pd.read_csv('./BankChurners.csv');\n","\n","data = df.copy()"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 10127 entries, 0 to 10126\n","Data columns (total 20 columns):\n"," #   Column                    Non-Null Count  Dtype  \n","---  ------                    --------------  -----  \n"," 0   Attrition_Flag            10127 non-null  object \n"," 1   Customer_Age              10127 non-null  int64  \n"," 2   Gender                    10127 non-null  object \n"," 3   Dependent_count           10127 non-null  int64  \n"," 4   Education_Level           8608 non-null   object \n"," 5   Marital_Status            9378 non-null   object \n"," 6   Income_Category           10127 non-null  object \n"," 7   Card_Category             10127 non-null  object \n"," 8   Months_on_book            10127 non-null  int64  \n"," 9   Total_Relationship_Count  10127 non-null  int64  \n"," 10  Months_Inactive_12_mon    10127 non-null  int64  \n"," 11  Contacts_Count_12_mon     10127 non-null  int64  \n"," 12  Credit_Limit              10127 non-null  float64\n"," 13  Total_Revolving_Bal       10127 non-null  int64  \n"," 14  Avg_Open_To_Buy           10127 non-null  float64\n"," 15  Total_Amt_Chng_Q4_Q1      10127 non-null  float64\n"," 16  Total_Trans_Amt           10127 non-null  int64  \n"," 17  Total_Trans_Ct            10127 non-null  int64  \n"," 18  Total_Ct_Chng_Q4_Q1       10127 non-null  float64\n"," 19  Avg_Utilization_Ratio     10127 non-null  float64\n","dtypes: float64(5), int64(9), object(6)\n","memory usage: 1.5+ MB\n"]}],"source":["data.drop(['CLIENTNUM'], axis=1, inplace=True)\n","data.info()"]},{"cell_type":"markdown","metadata":{"id":"UvpMDcaaMKtI"},"source":["## Data Overview"]},{"cell_type":"markdown","metadata":{"id":"tIiCRwqZ54_C"},"source":["- Observations\n","- Sanity checks"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"01hJQ7EfMKtK"},"outputs":[{"data":{"text/plain":["Attrition_Flag                 0\n","Customer_Age                   0\n","Gender                         0\n","Dependent_count                0\n","Education_Level             1519\n","Marital_Status               749\n","Income_Category                0\n","Card_Category                  0\n","Months_on_book                 0\n","Total_Relationship_Count       0\n","Months_Inactive_12_mon         0\n","Contacts_Count_12_mon          0\n","Credit_Limit                   0\n","Total_Revolving_Bal            0\n","Avg_Open_To_Buy                0\n","Total_Amt_Chng_Q4_Q1           0\n","Total_Trans_Amt                0\n","Total_Trans_Ct                 0\n","Total_Ct_Chng_Q4_Q1            0\n","Avg_Utilization_Ratio          0\n","dtype: int64"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["# check for missing values\n","data.isnull().sum()"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"text/plain":["Attrition_Flag              0\n","Customer_Age                0\n","Gender                      0\n","Dependent_count             0\n","Education_Level             0\n","Marital_Status              0\n","Income_Category             0\n","Card_Category               0\n","Months_on_book              0\n","Total_Relationship_Count    0\n","Months_Inactive_12_mon      0\n","Contacts_Count_12_mon       0\n","Credit_Limit                0\n","Total_Revolving_Bal         0\n","Avg_Open_To_Buy             0\n","Total_Amt_Chng_Q4_Q1        0\n","Total_Trans_Amt             0\n","Total_Trans_Ct              0\n","Total_Ct_Chng_Q4_Q1         0\n","Avg_Utilization_Ratio       0\n","dtype: int64"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["# imput the missing values for education level with mode as it is categorical\n","data['Education_Level'].fillna(data['Education_Level'].mode()[0], inplace=True)\n","\n","# imput the missing values for marital status with mode as it is categorical\n","data['Marital_Status'].fillna(data['Marital_Status'].mode()[0], inplace=True)\n","\n","data.isnull().sum()"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 10127 entries, 0 to 10126\n","Data columns (total 20 columns):\n"," #   Column                    Non-Null Count  Dtype   \n","---  ------                    --------------  -----   \n"," 0   Attrition_Flag            10127 non-null  category\n"," 1   Customer_Age              10127 non-null  int64   \n"," 2   Gender                    10127 non-null  category\n"," 3   Dependent_count           10127 non-null  int64   \n"," 4   Education_Level           10127 non-null  category\n"," 5   Marital_Status            10127 non-null  category\n"," 6   Income_Category           10127 non-null  category\n"," 7   Card_Category             10127 non-null  category\n"," 8   Months_on_book            10127 non-null  int64   \n"," 9   Total_Relationship_Count  10127 non-null  int64   \n"," 10  Months_Inactive_12_mon    10127 non-null  int64   \n"," 11  Contacts_Count_12_mon     10127 non-null  int64   \n"," 12  Credit_Limit              10127 non-null  float64 \n"," 13  Total_Revolving_Bal       10127 non-null  int64   \n"," 14  Avg_Open_To_Buy           10127 non-null  float64 \n"," 15  Total_Amt_Chng_Q4_Q1      10127 non-null  float64 \n"," 16  Total_Trans_Amt           10127 non-null  int64   \n"," 17  Total_Trans_Ct            10127 non-null  int64   \n"," 18  Total_Ct_Chng_Q4_Q1       10127 non-null  float64 \n"," 19  Avg_Utilization_Ratio     10127 non-null  float64 \n","dtypes: category(6), float64(5), int64(9)\n","memory usage: 1.1 MB\n","None\n","(10127, 20)\n"]}],"source":["# convert the data type of object variables to the categorical variables\n","for column in data.columns:\n","    if data[column].dtype == 'object':\n","        data[column] = data[column].astype('category')\n"," \n","print(data.info())\n","print(data.shape)\n"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"data":{"text/plain":["Attrition_Flag\n","Existing Customer    83.934038\n","Attrited Customer    16.065962\n","Name: proportion, dtype: float64"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["# attrition_flag is the target variable and check the distribution of the target variable in percentage\n","data['Attrition_Flag'].value_counts(normalize=True) * 100"]},{"cell_type":"markdown","metadata":{},"source":["### Summary\n","- Dataset has 10127 rows and 20 columns\n","- Education level and martial Status was having missing values and treated with imputing mode value of those column.\n","- Object data types are now convered to categorical type\n","- attrition_flag is imbalanced with 83% of existing customers and 16% of attrited customers and the modelmay be biased towards the majority class. We may need to treat with oversampling or undersampling later during model building.\n","- Droped Client number which is unique id for each customer and it will not have significant value in prediction.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"j-yGG8LNSSMa"},"source":["## Exploratory Data Analysis (EDA)"]},{"cell_type":"markdown","metadata":{"id":"3bGVKmh75ri8"},"source":["- EDA is an important part of any project involving data.\n","- It is important to investigate and understand the data better before building a model with it.\n","- A few questions have been mentioned below which will help you approach the analysis in the right manner and generate insights from the data.\n","- A thorough analysis of the data, in addition to the questions mentioned below, should be done."]},{"cell_type":"markdown","metadata":{"id":"oEyqzdJBb0jU"},"source":["**Questions**:\n","\n","1. How is the total transaction amount distributed?\n","2. What is the distribution of the level of education of customers?\n","3. What is the distribution of the level of income of customers?\n","4. How does the change in transaction amount between Q4 and Q1 (`total_ct_change_Q4_Q1`) vary by the customer's account status (`Attrition_Flag`)?\n","5. How does the number of months a customer was inactive in the last 12 months (`Months_Inactive_12_mon`) vary by the customer's account status (`Attrition_Flag`)?\n","6. What are the attributes that have a strong correlation with each other?\n","\n"]},{"cell_type":"markdown","metadata":{"id":"-YyWJgFlKlWM"},"source":["#### The below functions need to be defined to carry out the Exploratory Data Analysis."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QIP4bI3Zbp07"},"outputs":[],"source":["# function to plot a boxplot and a histogram along the same scale.\n","\n","\n","def histogram_boxplot(data, feature, figsize=(12, 7), kde=False, bins=None):\n","    \"\"\"\n","    Boxplot and histogram combined\n","\n","    data: dataframe\n","    feature: dataframe column\n","    figsize: size of figure (default (12,7))\n","    kde: whether to the show density curve (default False)\n","    bins: number of bins for histogram (default None)\n","    \"\"\"\n","    f2, (ax_box2, ax_hist2) = plt.subplots(\n","        nrows=2,  # Number of rows of the subplot grid= 2\n","        sharex=True,  # x-axis will be shared among all subplots\n","        gridspec_kw={\"height_ratios\": (0.25, 0.75)},\n","        figsize=figsize,\n","    )  # creating the 2 subplots\n","    sns.boxplot(\n","        data=data, x=feature, ax=ax_box2, showmeans=True, color=\"violet\"\n","    )  # boxplot will be created and a triangle will indicate the mean value of the column\n","    sns.histplot(\n","        data=data, x=feature, kde=kde, ax=ax_hist2, bins=bins, palette=\"winter\"\n","    ) if bins else sns.histplot(\n","        data=data, x=feature, kde=kde, ax=ax_hist2\n","    )  # For histogram\n","    ax_hist2.axvline(\n","        data[feature].mean(), color=\"green\", linestyle=\"--\"\n","    )  # Add mean to the histogram\n","    ax_hist2.axvline(\n","        data[feature].median(), color=\"black\", linestyle=\"-\"\n","    )  # Add median to the histogram"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5021de33"},"outputs":[],"source":["# function to create labeled barplots\n","\n","\n","def labeled_barplot(data, feature, perc=False, n=None):\n","    \"\"\"\n","    Barplot with percentage at the top\n","\n","    data: dataframe\n","    feature: dataframe column\n","    perc: whether to display percentages instead of count (default is False)\n","    n: displays the top n category levels (default is None, i.e., display all levels)\n","    \"\"\"\n","\n","    total = len(data[feature])  # length of the column\n","    count = data[feature].nunique()\n","    if n is None:\n","        plt.figure(figsize=(count + 1, 5))\n","    else:\n","        plt.figure(figsize=(n + 1, 5))\n","\n","    plt.xticks(rotation=90, fontsize=15)\n","    ax = sns.countplot(\n","        data=data,\n","        x=feature,\n","        palette=\"Paired\",\n","        order=data[feature].value_counts().index[:n].sort_values(),\n","    )\n","\n","    for p in ax.patches:\n","        if perc == True:\n","            label = \"{:.1f}%\".format(\n","                100 * p.get_height() / total\n","            )  # percentage of each class of the category\n","        else:\n","            label = p.get_height()  # count of each level of the category\n","\n","        x = p.get_x() + p.get_width() / 2  # width of the plot\n","        y = p.get_height()  # height of the plot\n","\n","        ax.annotate(\n","            label,\n","            (x, y),\n","            ha=\"center\",\n","            va=\"center\",\n","            size=12,\n","            xytext=(0, 5),\n","            textcoords=\"offset points\",\n","        )  # annotate the percentage\n","\n","    plt.show()  # show the plot"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c08fe5b8"},"outputs":[],"source":["# function to plot stacked bar chart\n","\n","def stacked_barplot(data, predictor, target):\n","    \"\"\"\n","    Print the category counts and plot a stacked bar chart\n","\n","    data: dataframe\n","    predictor: independent variable\n","    target: target variable\n","    \"\"\"\n","    count = data[predictor].nunique()\n","    sorter = data[target].value_counts().index[-1]\n","    tab1 = pd.crosstab(data[predictor], data[target], margins=True).sort_values(\n","        by=sorter, ascending=False\n","    )\n","    print(tab1)\n","    print(\"-\" * 120)\n","    tab = pd.crosstab(data[predictor], data[target], normalize=\"index\").sort_values(\n","        by=sorter, ascending=False\n","    )\n","    tab.plot(kind=\"bar\", stacked=True, figsize=(count + 1, 5))\n","    plt.legend(\n","        loc=\"lower left\", frameon=False,\n","    )\n","    plt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e90985c5"},"outputs":[],"source":["### Function to plot distributions\n","\n","def distribution_plot_wrt_target(data, predictor, target):\n","\n","    fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n","\n","    target_uniq = data[target].unique()\n","\n","    axs[0, 0].set_title(\"Distribution of target for target=\" + str(target_uniq[0]))\n","    sns.histplot(\n","        data=data[data[target] == target_uniq[0]],\n","        x=predictor,\n","        kde=True,\n","        ax=axs[0, 0],\n","        color=\"teal\",\n","    )\n","\n","    axs[0, 1].set_title(\"Distribution of target for target=\" + str(target_uniq[1]))\n","    sns.histplot(\n","        data=data[data[target] == target_uniq[1]],\n","        x=predictor,\n","        kde=True,\n","        ax=axs[0, 1],\n","        color=\"orange\",\n","    )\n","\n","    axs[1, 0].set_title(\"Boxplot w.r.t target\")\n","    sns.boxplot(data=data, x=target, y=predictor, ax=axs[1, 0], palette=\"gist_rainbow\")\n","\n","    axs[1, 1].set_title(\"Boxplot (without outliers) w.r.t target\")\n","    sns.boxplot(\n","        data=data,\n","        x=target,\n","        y=predictor,\n","        ax=axs[1, 1],\n","        showfliers=False,\n","        palette=\"gist_rainbow\",\n","    )\n","\n","    plt.tight_layout()\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"knk0w9XH4jao"},"source":["## Data Pre-processing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2JbJc1bX4jao"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"0J99-7Kubp09"},"source":["## Missing value imputation\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hke9uYOfBqoQ"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"OzOa9FGA6WtG"},"source":["## Model Building"]},{"cell_type":"markdown","metadata":{"id":"YZqmoqz7bp0-"},"source":["### Model evaluation criterion"]},{"cell_type":"markdown","metadata":{"id":"l2ORUgmUjDZC"},"source":["The nature of predictions made by the classification model will translate as follows:\n","\n","- True positives (TP) are failures correctly predicted by the model.\n","- False negatives (FN) are real failures in a generator where there is no detection by model.\n","- False positives (FP) are failure detections in a generator where there is no failure.\n","\n","**Which metric to optimize?**\n","\n","* We need to choose the metric which will ensure that the maximum number of generator failures are predicted correctly by the model.\n","* We would want Recall to be maximized as greater the Recall, the higher the chances of minimizing false negatives.\n","* We want to minimize false negatives because if a model predicts that a machine will have no failure when there will be a failure, it will increase the maintenance cost."]},{"cell_type":"markdown","metadata":{"id":"djQTqGKU4jap"},"source":["**Let's define a function to output different metrics (including recall) on the train and test set and a function to show confusion matrix so that we do not have to use the same code repetitively while evaluating models.**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bIekBxwp4jaq"},"outputs":[],"source":["# defining a function to compute different metrics to check performance of a classification model built using sklearn\n","def model_performance_classification_sklearn(model, predictors, target):\n","    \"\"\"\n","    Function to compute different metrics to check classification model performance\n","\n","    model: classifier\n","    predictors: independent variables\n","    target: dependent variable\n","    \"\"\"\n","\n","    # predicting using the independent variables\n","    pred = model.predict(predictors)\n","\n","    acc = accuracy_score(target, pred)  # to compute Accuracy\n","    recall = recall_score(target, pred)  # to compute Recall\n","    precision = precision_score(target, pred)  # to compute Precision\n","    f1 = f1_score(target, pred)  # to compute F1-score\n","\n","    # creating a dataframe of metrics\n","    df_perf = pd.DataFrame(\n","        {\n","            \"Accuracy\": acc,\n","            \"Recall\": recall,\n","            \"Precision\": precision,\n","            \"F1\": f1\n","\n","        },\n","        index=[0],\n","    )\n","\n","    return df_perf"]},{"cell_type":"markdown","metadata":{"id":"eqCDCbcw4jas"},"source":["### Model Building with original data"]},{"cell_type":"markdown","metadata":{"id":"dBtuhurlhKyp"},"source":["Sample code for model building with original data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V-tpzI7g4jas"},"outputs":[],"source":["models = []  # Empty list to store all the models\n","\n","# Appending models into the list\n","models.append((\"Bagging\", BaggingClassifier(random_state=1)))\n","models.append((\"Random forest\", RandomForestClassifier(random_state=1)))\n","'_______' ## Complete the code to append remaining 3 models in the list models\n","\n","print(\"\\n\" \"Training Performance:\" \"\\n\")\n","for name, model in models:\n","    model.fit(X_train, y_train)\n","    scores = recall_score(y_train, model.predict(X_train))\n","    print(\"{}: {}\".format(name, scores))\n","\n","print(\"\\n\" \"Validation Performance:\" \"\\n\")\n","\n","for name, model in models:\n","    model.fit(X_train, y_train)\n","    scores_val = recall_score(y_val, model.predict(X_val))\n","    print(\"{}: {}\".format(name, scores_val))"]},{"cell_type":"markdown","metadata":{"id":"oBKJaFU24jas"},"source":["### Model Building with Oversampled data\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FKxnygkE4jat"},"outputs":[],"source":["# Synthetic Minority Over Sampling Technique\n","sm = SMOTE(sampling_strategy=1, k_neighbors=5, random_state=1)\n","X_train_over, y_train_over = sm.fit_resample(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uYDlbnUO4jat"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"1aimb6bn4jat"},"source":["### Model Building with Undersampled data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DhxfTkvu4jat"},"outputs":[],"source":["# Random undersampler for under sampling the data\n","rus = RandomUnderSampler(random_state=1, sampling_strategy=1)\n","X_train_un, y_train_un = rus.fit_resample(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jROP_DVF4jau"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"yZGY1eL84jau"},"source":["### HyperparameterTuning"]},{"cell_type":"markdown","metadata":{"id":"rxM3jQuK_Pqc"},"source":["#### Sample Parameter Grids"]},{"cell_type":"markdown","metadata":{"id":"czq7BZ5b4jau"},"source":["**Hyperparameter tuning can take a long time to run, so to avoid that time complexity - you can use the following grids, wherever required.**\n","\n","- For Gradient Boosting:\n","\n","```\n","param_grid = {\n","    \"init\": [AdaBoostClassifier(random_state=1),DecisionTreeClassifier(random_state=1)],\n","    \"n_estimators\": np.arange(75,150,25),\n","    \"learning_rate\": [0.1, 0.01, 0.2, 0.05, 1],\n","    \"subsample\":[0.5,0.7,1],\n","    \"max_features\":[0.5,0.7,1],\n","}\n","```\n","\n","- For Adaboost:\n","\n","```\n","param_grid = {\n","     \"n_estimators\": np.arange(10, 110, 10),\n","     \"learning_rate\": [0.1, 0.01, 0.2, 0.05, 1],\n","     \"base_estimator\": [\n","         DecisionTreeClassifier(max_depth=1, random_state=1),\n","         DecisionTreeClassifier(max_depth=2, random_state=1),\n","         DecisionTreeClassifier(max_depth=3, random_state=1),\n","    ]\n","}\n","```\n","\n","- For Bagging Classifier:\n","\n","```\n","param_grid = {\n","    'max_samples': [0.8,0.9,1],\n","    'max_features': [0.7,0.8,0.9],\n","    'n_estimators' : [30,50,70],\n","}\n","```\n","- For Random Forest:\n","\n","```\n","param_grid = {\n","    \"n_estimators\": [200,250,300],\n","    \"min_samples_leaf\": np.arange(1, 4),\n","    \"max_features\": [np.arange(0.3, 0.6, 0.1),'sqrt'],\n","    \"max_samples\": np.arange(0.4, 0.7, 0.1)\n","}\n","```\n","\n","- For Decision Trees:\n","\n","```\n","param_grid = {\n","    'max_depth': np.arange(2,6),\n","    'min_samples_leaf': [1, 4, 7],\n","    'max_leaf_nodes' : [10, 15],\n","    'min_impurity_decrease': [0.0001,0.001]\n","}\n","```\n","\n","- For XGBoost:\n","\n","```\n","param_grid={\n","   'n_estimators':np.arange(50,300,50),\n","   'scale_pos_weight':[0,1,2,5,10],\n","   'learning_rate':[0.01,0.1,0.2,0.05],\n","   'gamma':[0,1,3,5],\n","   'subsample':[0.7,0.8,0.9,1]\n","}\n","```"]},{"cell_type":"markdown","metadata":{"id":"GMReRXdH_YUd"},"source":["#### Sample tuning method for Decision tree with original data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o9kks1hG_Xhy"},"outputs":[],"source":["# defining model\n","Model = DecisionTreeClassifier(random_state=1)\n","\n","# Parameter grid to pass in RandomSearchCV\n","param_grid = {'max_depth': np.arange(2,6),\n","              'min_samples_leaf': [1, 4, 7],\n","              'max_leaf_nodes' : [10,15],\n","              'min_impurity_decrease': [0.0001,0.001] }\n","\n","#Calling RandomizedSearchCV\n","randomized_cv = RandomizedSearchCV(estimator=Model, param_distributions=param_grid, n_iter=10, n_jobs = -1, scoring=scorer, cv=5, random_state=1)\n","\n","#Fitting parameters in RandomizedSearchCV\n","randomized_cv.fit(X_train,y_train)\n","\n","print(\"Best parameters are {} with CV score={}:\" .format(randomized_cv.best_params_,randomized_cv.best_score_))"]},{"cell_type":"markdown","metadata":{"id":"chN8hbfThKyr"},"source":["#### Sample tuning method for Decision tree with oversampled data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tVZcJ0hv4jau"},"outputs":[],"source":["# defining model\n","Model = DecisionTreeClassifier(random_state=1)\n","\n","# Parameter grid to pass in RandomSearchCV\n","param_grid = {'max_depth': np.arange(2,6),\n","              'min_samples_leaf': [1, 4, 7],\n","              'max_leaf_nodes' : [10,15],\n","              'min_impurity_decrease': [0.0001,0.001] }\n","\n","#Calling RandomizedSearchCV\n","randomized_cv = RandomizedSearchCV(estimator=Model, param_distributions=param_grid, n_iter=10, n_jobs = -1, scoring=scorer, cv=5, random_state=1)\n","\n","#Fitting parameters in RandomizedSearchCV\n","randomized_cv.fit(X_train_over,y_train_over)\n","\n","print(\"Best parameters are {} with CV score={}:\" .format(randomized_cv.best_params_,randomized_cv.best_score_))"]},{"cell_type":"markdown","metadata":{"id":"HtPIiIS7hKyr"},"source":["#### Sample tuning method for Decision tree with undersampled data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5pbdykhHhKyr"},"outputs":[],"source":["# defining model\n","Model = DecisionTreeClassifier(random_state=1)\n","\n","# Parameter grid to pass in RandomSearchCV\n","param_grid = {'max_depth': np.arange(2,20),\n","              'min_samples_leaf': [1, 2, 5, 7],\n","              'max_leaf_nodes' : [5, 10,15],\n","              'min_impurity_decrease': [0.0001,0.001] }\n","\n","#Calling RandomizedSearchCV\n","randomized_cv = RandomizedSearchCV(estimator=Model, param_distributions=param_grid, n_iter=10, n_jobs = -1, scoring=scorer, cv=5, random_state=1)\n","\n","#Fitting parameters in RandomizedSearchCV\n","randomized_cv.fit(X_train_un,y_train_un)\n","\n","print(\"Best parameters are {} with CV score={}:\" .format(randomized_cv.best_params_,randomized_cv.best_score_))"]},{"cell_type":"markdown","metadata":{"id":"D9JNnpxa4jau"},"source":["## Model Comparison and Final Model Selection"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0JG85rkY4jav"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"d_pDMFAz4jav"},"source":["### Test set final performance"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g8-epsXv4jav"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"c5hPmHyR4jaw"},"source":["# Business Insights and Conclusions"]},{"cell_type":"markdown","metadata":{"id":"VB3eO21n_sgt"},"source":["***"]}],"metadata":{"colab":{"collapsed_sections":["9EaJ8AGwpM-2","v_-uuGqH-qTt","xxhpZv9y-qTw","UvpMDcaaMKtI","j-yGG8LNSSMa","-YyWJgFlKlWM","knk0w9XH4jao","0J99-7Kubp09","OzOa9FGA6WtG","YZqmoqz7bp0-","eqCDCbcw4jas","oBKJaFU24jas","1aimb6bn4jat","yZGY1eL84jau","rxM3jQuK_Pqc","GMReRXdH_YUd","chN8hbfThKyr","HtPIiIS7hKyr","D9JNnpxa4jau","d_pDMFAz4jav","c5hPmHyR4jaw"],"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
